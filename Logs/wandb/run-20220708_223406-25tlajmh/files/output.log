GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type             | Params
-------------------------------------------------
0 | model       | Simple_QHN       | 170 K
1 | get_metrics | MetricCollection | 0
-------------------------------------------------
170 K     Trainable params
0         Non-trainable params
170 K     Total params
0.681     Total estimated model params size (MB)
Epoch 0:   0%|                                                                                                                                | 0/14 [00:00<?, ?it/s]
Missing logger folder: Logs/QML-Real_Machine/version000/NYU
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
  rank_zero_warn(
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
  rank_zero_warn(
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
Epoch 0:   0%|                                                                                                                                | 0/14 [00:00<?, ?it/s]tensor([[ 0.0647,  0.7000,  0.0201,  0.0013],
        [-0.1803,  0.5551, -0.3434, -0.1878],
        [ 0.0375,  0.7907, -0.1798,  0.2090],
        [ 0.1129,  0.4348, -0.2725,  0.1220],
        [ 0.1858,  0.3424, -0.0506, -0.0752],
        [ 0.3640,  0.4049, -0.0907,  0.1478],
        [ 0.4478,  0.9083,  0.2062,  0.3274],
        [ 0.4586,  0.6411, -0.3223,  0.2114],
        [ 0.1582,  0.4920, -0.2258,  0.1486],
        [ 0.2490,  0.7169, -0.4709,  0.0872],
        [-0.2039,  0.8111, -0.0307,  0.0059],
        [-0.3005,  0.7976, -0.3426,  0.0423],
        [ 0.2888,  0.4719, -0.0121,  0.3563],
        [ 0.1694,  0.5569, -0.0938, -0.0726],
        [ 0.3589,  0.4389, -0.3645,  0.0065],
        [-0.0343,  0.5228, -0.0691,  0.1293],
        [-0.2360,  0.7534,  0.2958,  0.1150],
        [-0.0961,  0.6756,  0.2411,  0.1623],
        [ 0.1106,  0.6602,  0.1193,  0.2510],
        [ 0.3136,  0.7680,  0.1671,  0.2520],
        [ 0.5172,  0.6931, -0.0150,  0.3192],
        [ 0.3761,  0.3272, -0.2218,  0.2328],
        [-0.0194,  0.3813,  0.2069,  0.2564],
        [-0.1211,  0.6440,  0.1654,  0.3996],
        [-0.3828,  0.6414,  0.4610,  0.5695],
        [-0.0674,  0.3263,  0.3662,  0.6029],
        [ 0.0806,  0.5143,  0.2887,  0.4103],
        [-0.1485,  0.4617,  0.5829,  0.3608],
        [-0.1921,  0.4493,  0.6189,  0.1730],
        [-0.3325,  0.5884,  0.2584,  0.0458],
        [-0.1142,  0.0520,  0.0137,  0.2330],
        [-0.0188,  0.0111, -0.1617, -0.0664]], device='cuda:0',
       grad_fn=<MulBackward0>)
tensor([0.0647, 0.7000, 0.0201, 0.0013], device='cuda:0', requires_grad=True)
tensor([-0.1803,  0.5551, -0.3434, -0.1878], device='cuda:0',
       requires_grad=True)
tensor([ 0.0375,  0.7907, -0.1798,  0.2090], device='cuda:0',
       requires_grad=True)
tensor([ 0.1129,  0.4348, -0.2725,  0.1220], device='cuda:0',
       requires_grad=True)
tensor([ 0.1858,  0.3424, -0.0506, -0.0752], device='cuda:0',
       requires_grad=True)
tensor([ 0.3640,  0.4049, -0.0907,  0.1478], device='cuda:0',
       requires_grad=True)
tensor([0.4478, 0.9083, 0.2062, 0.3274], device='cuda:0', requires_grad=True)
tensor([ 0.4586,  0.6411, -0.3223,  0.2114], device='cuda:0',
       requires_grad=True)
tensor([ 0.1582,  0.4920, -0.2258,  0.1486], device='cuda:0',
       requires_grad=True)
tensor([ 0.2490,  0.7169, -0.4709,  0.0872], device='cuda:0',
       requires_grad=True)
tensor([-0.2039,  0.8111, -0.0307,  0.0059], device='cuda:0',
       requires_grad=True)
tensor([-0.3005,  0.7976, -0.3426,  0.0423], device='cuda:0',
       requires_grad=True)
tensor([ 0.2888,  0.4719, -0.0121,  0.3563], device='cuda:0',
       requires_grad=True)
tensor([ 0.1694,  0.5569, -0.0938, -0.0726], device='cuda:0',
       requires_grad=True)
tensor([ 0.3589,  0.4389, -0.3645,  0.0065], device='cuda:0',
       requires_grad=True)
tensor([-0.0343,  0.5228, -0.0691,  0.1293], device='cuda:0',
       requires_grad=True)
tensor([-0.2360,  0.7534,  0.2958,  0.1150], device='cuda:0',
       requires_grad=True)
tensor([-0.0961,  0.6756,  0.2411,  0.1623], device='cuda:0',
       requires_grad=True)
tensor([0.1106, 0.6602, 0.1193, 0.2510], device='cuda:0', requires_grad=True)
tensor([0.3136, 0.7680, 0.1671, 0.2520], device='cuda:0', requires_grad=True)
tensor([ 0.5172,  0.6931, -0.0150,  0.3192], device='cuda:0',
       requires_grad=True)
tensor([ 0.3761,  0.3272, -0.2218,  0.2328], device='cuda:0',
       requires_grad=True)
tensor([-0.0194,  0.3813,  0.2069,  0.2564], device='cuda:0',
       requires_grad=True)
tensor([-0.1211,  0.6440,  0.1654,  0.3996], device='cuda:0',
       requires_grad=True)
tensor([-0.3828,  0.6414,  0.4610,  0.5695], device='cuda:0',
       requires_grad=True)
tensor([-0.0674,  0.3263,  0.3662,  0.6029], device='cuda:0',
       requires_grad=True)
tensor([0.0806, 0.5143, 0.2887, 0.4103], device='cuda:0', requires_grad=True)
tensor([-0.1485,  0.4617,  0.5829,  0.3608], device='cuda:0',
       requires_grad=True)
tensor([-0.1921,  0.4493,  0.6189,  0.1730], device='cuda:0',
       requires_grad=True)
tensor([-0.3325,  0.5884,  0.2584,  0.0458], device='cuda:0',
       requires_grad=True)
tensor([-0.1142,  0.0520,  0.0137,  0.2330], device='cuda:0',
       requires_grad=True)
tensor([-0.0188,  0.0111, -0.1617, -0.0664], device='cuda:0',
       requires_grad=True)
[[0.66471459 1.29996226 0.62005119 0.60131564]
 [0.41966539 1.15510181 0.25659362 0.41218083]
 [0.63748361 1.39074222 0.42016088 0.80904465]
 [0.712904   1.03478161 0.32751567 0.7220201 ]
 [0.78577221 0.94236413 0.5493542  0.52481381]
 [0.96398429 1.00490544 0.50932649 0.74782818]
 [1.04781998 1.50828437 0.80621696 0.92738087]
 [1.05860705 1.24109552 0.27769876 0.81136419]
 [0.75823539 1.09200231 0.374151   0.74856492]
 [0.84896334 1.31687251 0.12908662 0.68716552]
 [0.39608095 1.41108063 0.56926392 0.60587044]
 [0.29948807 1.39756856 0.25739134 0.64225877]
 [0.8888076  1.07185045 0.58788147 0.95630798]
 [0.76939639 1.15687672 0.50621895 0.52737406]
 [0.9588644  1.03894181 0.23549101 0.60648795]
 [0.565671   1.12278739 0.53086001 0.72930423]
 [0.36397042 1.35341868 0.89581755 0.71496916]
 [0.50391957 1.27556995 0.84113846 0.76227075]
 [0.71060136 1.26022944 0.7192613  0.85102726]
 [0.91359556 1.36799673 0.76711411 0.8520487 ]
 [1.11720744 1.29308585 0.58497266 0.9192285 ]
 [0.97607104 0.9272028  0.37819933 0.83276079]
 [0.5805872  0.98125515 0.80691949 0.8564258 ]
 [0.47890748 1.24398664 0.76538249 0.99962992]
 [0.21723343 1.24141655 1.06096784 1.16948555]
 [0.53262869 0.92625616 0.96618954 1.20289645]
 [0.68056072 1.11432085 0.88867841 1.0103162 ]
 [0.4514557  1.06166283 1.18286667 0.96079541]
 [0.40793791 1.04929507 1.21894107 0.77299582]
 [0.26747683 1.18843833 0.85836322 0.64581108]
 [0.48582037 0.65196513 0.6136605  0.83303205]
 [0.58120632 0.61113015 0.43825469 0.53358131]]
[0.66471459 1.29996226 0.62005119 0.60131564]
[0.41966539 1.15510181 0.25659362 0.41218083]
[0.63748361 1.39074222 0.42016088 0.80904465]
[0.712904   1.03478161 0.32751567 0.7220201 ]
[0.78577221 0.94236413 0.5493542  0.52481381]
[0.96398429 1.00490544 0.50932649 0.74782818]
[1.04781998 1.50828437 0.80621696 0.92738087]
[1.05860705 1.24109552 0.27769876 0.81136419]
[0.75823539 1.09200231 0.374151   0.74856492]
[0.84896334 1.31687251 0.12908662 0.68716552]
[0.39608095 1.41108063 0.56926392 0.60587044]
[0.29948807 1.39756856 0.25739134 0.64225877]
[0.8888076  1.07185045 0.58788147 0.95630798]
[0.76939639 1.15687672 0.50621895 0.52737406]
[0.9588644  1.03894181 0.23549101 0.60648795]
[0.565671   1.12278739 0.53086001 0.72930423]
[0.36397042 1.35341868 0.89581755 0.71496916]
[0.50391957 1.27556995 0.84113846 0.76227075]
[0.71060136 1.26022944 0.7192613  0.85102726]
[0.91359556 1.36799673 0.76711411 0.8520487 ]
[1.11720744 1.29308585 0.58497266 0.9192285 ]
[0.97607104 0.9272028  0.37819933 0.83276079]
[0.5805872  0.98125515 0.80691949 0.8564258 ]
[0.47890748 1.24398664 0.76538249 0.99962992]
[0.21723343 1.24141655 1.06096784 1.16948555]
[0.53262869 0.92625616 0.96618954 1.20289645]
[0.68056072 1.11432085 0.88867841 1.0103162 ]
[0.4514557  1.06166283 1.18286667 0.96079541]
[0.40793791 1.04929507 1.21894107 0.77299582]
[0.26747683 1.18843833 0.85836322 0.64581108]
[0.48582037 0.65196513 0.6136605  0.83303205]
