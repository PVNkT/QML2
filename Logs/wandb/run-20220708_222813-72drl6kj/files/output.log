GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Epoch 0:   0%|                                                                                                                                | 0/14 [00:00<?, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type             | Params
-------------------------------------------------
0 | model       | Simple_QHN       | 170 K
1 | get_metrics | MetricCollection | 0
-------------------------------------------------
170 K     Trainable params
0         Non-trainable params
170 K     Total params
0.681     Total estimated model params size (MB)
Missing logger folder: Logs/QML-Real_Machine/version000/NYU
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
  rank_zero_warn(
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
Epoch 0:   0%|                                                                                                                                | 0/14 [00:00<?, ?it/s]tensor([[ 0.0647,  0.7000,  0.0201,  0.0013],
        [-0.1803,  0.5551, -0.3434, -0.1878],
        [ 0.0375,  0.7907, -0.1798,  0.2090],
        [ 0.1129,  0.4348, -0.2725,  0.1220],
        [ 0.1858,  0.3424, -0.0506, -0.0752],
        [ 0.3640,  0.4049, -0.0907,  0.1478],
        [ 0.4478,  0.9083,  0.2062,  0.3274],
        [ 0.4586,  0.6411, -0.3223,  0.2114],
        [ 0.1582,  0.4920, -0.2258,  0.1486],
        [ 0.2490,  0.7169, -0.4709,  0.0872],
        [-0.2039,  0.8111, -0.0307,  0.0059],
        [-0.3005,  0.7976, -0.3426,  0.0423],
        [ 0.2888,  0.4719, -0.0121,  0.3563],
        [ 0.1694,  0.5569, -0.0938, -0.0726],
        [ 0.3589,  0.4389, -0.3645,  0.0065],
        [-0.0343,  0.5228, -0.0691,  0.1293],
        [-0.2360,  0.7534,  0.2958,  0.1150],
        [-0.0961,  0.6756,  0.2411,  0.1623],
        [ 0.1106,  0.6602,  0.1193,  0.2510],
        [ 0.3136,  0.7680,  0.1671,  0.2520],
        [ 0.5172,  0.6931, -0.0150,  0.3192],
        [ 0.3761,  0.3272, -0.2218,  0.2328],
        [-0.0194,  0.3813,  0.2069,  0.2564],
        [-0.1211,  0.6440,  0.1654,  0.3996],
        [-0.3828,  0.6414,  0.4610,  0.5695],
        [-0.0674,  0.3263,  0.3662,  0.6029],
        [ 0.0806,  0.5143,  0.2887,  0.4103],
        [-0.1485,  0.4617,  0.5829,  0.3608],
        [-0.1921,  0.4493,  0.6189,  0.1730],
        [-0.3325,  0.5884,  0.2584,  0.0458],
        [-0.1142,  0.0520,  0.0137,  0.2330],
        [-0.0188,  0.0111, -0.1617, -0.0664]], device='cuda:0',
       grad_fn=<MulBackward0>)
[0.06471459 0.69996226 0.02005119 0.00131564]
[-0.18033461  0.5551018  -0.34340638 -0.18781917]
[ 0.03748361  0.7907422  -0.17983912  0.20904465]
[ 0.112904    0.4347816  -0.27248433  0.1220201 ]
[ 0.18577221  0.34236413 -0.0506458  -0.07518619]
[ 0.3639843   0.40490544 -0.09067351  0.14782818]
[0.44781998 0.90828437 0.20621696 0.32738087]
[ 0.45860705  0.6410955  -0.32230124  0.2113642 ]
[ 0.15823539  0.4920023  -0.225849    0.14856492]
[ 0.24896334  0.7168725  -0.47091338  0.08716552]
[-0.20391905  0.81108063 -0.03073608  0.00587044]
[-0.30051193  0.79756856 -0.34260866  0.04225877]
[ 0.2888076   0.47185045 -0.01211853  0.35630798]
[ 0.16939639  0.5568767  -0.09378105 -0.07262594]
[ 0.3588644   0.4389418  -0.364509    0.00648795]
[-0.034329    0.5227874  -0.06913999  0.12930423]
[-0.23602958  0.7534187   0.29581755  0.11496916]
[-0.09608043  0.67556995  0.24113846  0.16227075]
[0.11060136 0.66022944 0.1192613  0.25102726]
[0.31359556 0.7679967  0.16711411 0.2520487 ]
[ 0.51720744  0.69308585 -0.01502734  0.3192285 ]
[ 0.37607104  0.3272028  -0.22180067  0.23276079]
[-0.0194128   0.38125515  0.20691949  0.2564258 ]
[-0.12109252  0.64398664  0.16538249  0.39962992]
[-0.38276657  0.64141655  0.46096784  0.56948555]
[-0.06737131  0.32625616  0.36618954  0.60289645]
[0.08056072 0.51432085 0.2886784  0.4103162 ]
[-0.1485443   0.46166283  0.58286667  0.3607954 ]
[-0.1920621   0.44929507  0.61894107  0.17299582]
[-0.33252317  0.58843833  0.25836322  0.04581108]
[-0.11417963  0.05196513  0.0136605   0.23303205]
[-0.01879368  0.01113015 -0.16174531 -0.06641869]
[0.66471459 1.29996226 0.62005119 0.60131564]
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
  rank_zero_warn(
Traceback (most recent call last):
  File "run.py", line 26, in <module>
    main()
  File "run.py", line 21, in main
    metrics = runner.run(profiler=cfg.get("profiler", "simple"))
  File "/home/sol/git/QML2/src/runners/runner.py", line 164, in run
    trainer.fit(model, datamodule=dm)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 768, in fit
    self._call_and_handle_interrupt(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 721, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 809, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1234, in _run
    results = self._run_stage()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1321, in _run_stage
    return self._run_train()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1351, in _run_train
    self.fit_loop.run()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1593, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1625, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 109, in wrapper
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 143, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 311, in backward_fn
    self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1763, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 168, in backward
    self.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 80, in backward
    model.backward(closure_loss, optimizer, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1370, in backward
    loss.backward(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/function.py", line 253, in apply
    return user_fn(self, *args)
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 121, in backward
    expectation_right = ctx.quantum_circuit(ctx.n_qubits, ctx.backend, ctx.shots, thetas =shift_right[i]).run()
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 25, in __init__
    for theta in np.array(self.thetas.cpu()):
AttributeError: 'numpy.ndarray' object has no attribute 'cpu'
Traceback (most recent call last):
  File "run.py", line 26, in <module>
    main()
  File "run.py", line 21, in main
    metrics = runner.run(profiler=cfg.get("profiler", "simple"))
  File "/home/sol/git/QML2/src/runners/runner.py", line 164, in run
    trainer.fit(model, datamodule=dm)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 768, in fit
    self._call_and_handle_interrupt(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 721, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 809, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1234, in _run
    results = self._run_stage()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1321, in _run_stage
    return self._run_train()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1351, in _run_train
    self.fit_loop.run()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1593, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1625, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 109, in wrapper
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 143, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 311, in backward_fn
    self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1763, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 168, in backward
    self.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 80, in backward
    model.backward(closure_loss, optimizer, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1370, in backward
    loss.backward(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/function.py", line 253, in apply
    return user_fn(self, *args)
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 121, in backward
    expectation_right = ctx.quantum_circuit(ctx.n_qubits, ctx.backend, ctx.shots, thetas =shift_right[i]).run()
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 25, in __init__
    for theta in np.array(self.thetas.cpu()):
AttributeError: 'numpy.ndarray' object has no attribute 'cpu'
Traceback (most recent call last):
  File "run.py", line 26, in <module>
    main()
  File "run.py", line 21, in main
    metrics = runner.run(profiler=cfg.get("profiler", "simple"))
  File "/home/sol/git/QML2/src/runners/runner.py", line 164, in run
    trainer.fit(model, datamodule=dm)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 768, in fit
    self._call_and_handle_interrupt(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 721, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 809, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1234, in _run
    results = self._run_stage()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1321, in _run_stage
    return self._run_train()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1351, in _run_train
    self.fit_loop.run()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1593, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1625, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 109, in wrapper
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 143, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 311, in backward_fn
    self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1763, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 168, in backward
    self.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 80, in backward
    model.backward(closure_loss, optimizer, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1370, in backward
    loss.backward(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/function.py", line 253, in apply
    return user_fn(self, *args)
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 121, in backward
    expectation_right = ctx.quantum_circuit(ctx.n_qubits, ctx.backend, ctx.shots, thetas =shift_right[i]).run()
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 25, in __init__
    for theta in np.array(self.thetas.cpu()):
