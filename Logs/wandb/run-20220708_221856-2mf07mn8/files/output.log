GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Epoch 0:   0%|                                                                                                                                | 0/14 [00:00<?, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name        | Type             | Params
-------------------------------------------------
0 | model       | Simple_QHN       | 170 K
1 | get_metrics | MetricCollection | 0
-------------------------------------------------
170 K     Trainable params
0         Non-trainable params
170 K     Total params
0.681     Total estimated model params size (MB)
Missing logger folder: Logs/QML-Real_Machine/version000/NYU
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
  rank_zero_warn(
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
  rank_zero_warn(
/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2708: UserWarning: Using trainer.logger when Trainer is configured to use multiple loggers. This behavior will change in v1.8 when LoggerCollection is removed, and trainer.logger will return the first logger in trainer.loggers
Epoch 0:   0%|                                                                                                                                | 0/14 [00:00<?, ?it/s]tensor([[ 0.0647,  0.7000,  0.0201,  0.0013],
        [-0.1803,  0.5551, -0.3434, -0.1878],
        [ 0.0375,  0.7907, -0.1798,  0.2090],
        [ 0.1129,  0.4348, -0.2725,  0.1220],
        [ 0.1858,  0.3424, -0.0506, -0.0752],
        [ 0.3640,  0.4049, -0.0907,  0.1478],
        [ 0.4478,  0.9083,  0.2062,  0.3274],
        [ 0.4586,  0.6411, -0.3223,  0.2114],
        [ 0.1582,  0.4920, -0.2258,  0.1486],
        [ 0.2490,  0.7169, -0.4709,  0.0872],
        [-0.2039,  0.8111, -0.0307,  0.0059],
        [-0.3005,  0.7976, -0.3426,  0.0423],
        [ 0.2888,  0.4719, -0.0121,  0.3563],
        [ 0.1694,  0.5569, -0.0938, -0.0726],
        [ 0.3589,  0.4389, -0.3645,  0.0065],
        [-0.0343,  0.5228, -0.0691,  0.1293],
        [-0.2360,  0.7534,  0.2958,  0.1150],
        [-0.0961,  0.6756,  0.2411,  0.1623],
        [ 0.1106,  0.6602,  0.1193,  0.2510],
        [ 0.3136,  0.7680,  0.1671,  0.2520],
        [ 0.5172,  0.6931, -0.0150,  0.3192],
        [ 0.3761,  0.3272, -0.2218,  0.2328],
        [-0.0194,  0.3813,  0.2069,  0.2564],
        [-0.1211,  0.6440,  0.1654,  0.3996],
        [-0.3828,  0.6414,  0.4610,  0.5695],
        [-0.0674,  0.3263,  0.3662,  0.6029],
        [ 0.0806,  0.5143,  0.2887,  0.4103],
        [-0.1485,  0.4617,  0.5829,  0.3608],
        [-0.1921,  0.4493,  0.6189,  0.1730],
        [-0.3325,  0.5884,  0.2584,  0.0458],
        [-0.1142,  0.0520,  0.0137,  0.2330],
        [-0.0188,  0.0111, -0.1617, -0.0664]], device='cuda:0',
       grad_fn=<MulBackward0>)
tensor([0.0647, 0.7000, 0.0201, 0.0013], device='cuda:0', requires_grad=True)
tensor([-0.1803,  0.5551, -0.3434, -0.1878], device='cuda:0',
       requires_grad=True)
tensor([ 0.0375,  0.7907, -0.1798,  0.2090], device='cuda:0',
       requires_grad=True)
tensor([ 0.1129,  0.4348, -0.2725,  0.1220], device='cuda:0',
       requires_grad=True)
tensor([ 0.1858,  0.3424, -0.0506, -0.0752], device='cuda:0',
       requires_grad=True)
tensor([ 0.3640,  0.4049, -0.0907,  0.1478], device='cuda:0',
       requires_grad=True)
tensor([0.4478, 0.9083, 0.2062, 0.3274], device='cuda:0', requires_grad=True)
tensor([ 0.4586,  0.6411, -0.3223,  0.2114], device='cuda:0',
       requires_grad=True)
tensor([ 0.1582,  0.4920, -0.2258,  0.1486], device='cuda:0',
       requires_grad=True)
tensor([ 0.2490,  0.7169, -0.4709,  0.0872], device='cuda:0',
       requires_grad=True)
tensor([-0.2039,  0.8111, -0.0307,  0.0059], device='cuda:0',
       requires_grad=True)
tensor([-0.3005,  0.7976, -0.3426,  0.0423], device='cuda:0',
       requires_grad=True)
tensor([ 0.2888,  0.4719, -0.0121,  0.3563], device='cuda:0',
       requires_grad=True)
tensor([ 0.1694,  0.5569, -0.0938, -0.0726], device='cuda:0',
       requires_grad=True)
tensor([ 0.3589,  0.4389, -0.3645,  0.0065], device='cuda:0',
       requires_grad=True)
tensor([-0.0343,  0.5228, -0.0691,  0.1293], device='cuda:0',
       requires_grad=True)
tensor([-0.2360,  0.7534,  0.2958,  0.1150], device='cuda:0',
       requires_grad=True)
tensor([-0.0961,  0.6756,  0.2411,  0.1623], device='cuda:0',
       requires_grad=True)
tensor([0.1106, 0.6602, 0.1193, 0.2510], device='cuda:0', requires_grad=True)
tensor([0.3136, 0.7680, 0.1671, 0.2520], device='cuda:0', requires_grad=True)
tensor([ 0.5172,  0.6931, -0.0150,  0.3192], device='cuda:0',
       requires_grad=True)
tensor([ 0.3761,  0.3272, -0.2218,  0.2328], device='cuda:0',
       requires_grad=True)
tensor([-0.0194,  0.3813,  0.2069,  0.2564], device='cuda:0',
       requires_grad=True)
tensor([-0.1211,  0.6440,  0.1654,  0.3996], device='cuda:0',
       requires_grad=True)
tensor([-0.3828,  0.6414,  0.4610,  0.5695], device='cuda:0',
       requires_grad=True)
tensor([-0.0674,  0.3263,  0.3662,  0.6029], device='cuda:0',
       requires_grad=True)
tensor([0.0806, 0.5143, 0.2887, 0.4103], device='cuda:0', requires_grad=True)
tensor([-0.1485,  0.4617,  0.5829,  0.3608], device='cuda:0',
       requires_grad=True)
tensor([-0.1921,  0.4493,  0.6189,  0.1730], device='cuda:0',
       requires_grad=True)
tensor([-0.3325,  0.5884,  0.2584,  0.0458], device='cuda:0',
       requires_grad=True)
tensor([-0.1142,  0.0520,  0.0137,  0.2330], device='cuda:0',
       requires_grad=True)
tensor([-0.0188,  0.0111, -0.1617, -0.0664], device='cuda:0',
       requires_grad=True)
[0.66471459 1.29996226 0.62005119 0.60131564]
0.6647145882248878
Traceback (most recent call last):
  File "run.py", line 26, in <module>
    main()
  File "run.py", line 21, in main
    metrics = runner.run(profiler=cfg.get("profiler", "simple"))
  File "/home/sol/git/QML2/src/runners/runner.py", line 164, in run
    trainer.fit(model, datamodule=dm)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 768, in fit
    self._call_and_handle_interrupt(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 721, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 809, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1234, in _run
    results = self._run_stage()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1321, in _run_stage
    return self._run_train()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1351, in _run_train
    self.fit_loop.run()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1593, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1625, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 109, in wrapper
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 143, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 311, in backward_fn
    self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1763, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 168, in backward
    self.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 80, in backward
    model.backward(closure_loss, optimizer, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1370, in backward
    loss.backward(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/function.py", line 253, in apply
    return user_fn(self, *args)
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 119, in backward
    expectation_right = ctx.quantum_circuit(ctx.n_qubits, ctx.backend, ctx.shots, thetas =shift_right[i]).run()
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 31, in __init__
    for i in range(len(theta)):
TypeError: object of type 'numpy.float64' has no len()
Traceback (most recent call last):
  File "run.py", line 26, in <module>
    main()
  File "run.py", line 21, in main
    metrics = runner.run(profiler=cfg.get("profiler", "simple"))
  File "/home/sol/git/QML2/src/runners/runner.py", line 164, in run
    trainer.fit(model, datamodule=dm)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 768, in fit
    self._call_and_handle_interrupt(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 721, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 809, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1234, in _run
    results = self._run_stage()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1321, in _run_stage
    return self._run_train()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1351, in _run_train
    self.fit_loop.run()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1593, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1625, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 109, in wrapper
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 143, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 311, in backward_fn
    self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1763, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 168, in backward
    self.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 80, in backward
    model.backward(closure_loss, optimizer, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1370, in backward
    loss.backward(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/function.py", line 253, in apply
    return user_fn(self, *args)
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 119, in backward
    expectation_right = ctx.quantum_circuit(ctx.n_qubits, ctx.backend, ctx.shots, thetas =shift_right[i]).run()
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 31, in __init__
    for i in range(len(theta)):
TypeError: object of type 'numpy.float64' has no len()
Traceback (most recent call last):
  File "run.py", line 26, in <module>
    main()
  File "run.py", line 21, in main
    metrics = runner.run(profiler=cfg.get("profiler", "simple"))
  File "/home/sol/git/QML2/src/runners/runner.py", line 164, in run
    trainer.fit(model, datamodule=dm)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 768, in fit
    self._call_and_handle_interrupt(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 721, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 809, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1234, in _run
    results = self._run_stage()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1321, in _run_stage
    return self._run_train()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1351, in _run_train
    self.fit_loop.run()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 269, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 256, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 369, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1593, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1625, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 193, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 155, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/optimizer.py", line 109, in wrapper
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 140, in _wrap_closure
    closure_result = closure()
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 143, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 311, in backward_fn
    self.trainer._call_strategy_hook("backward", loss, optimizer, opt_idx)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1763, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py", line 168, in backward
    self.precision_plugin.backward(self.lightning_module, closure_loss, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 80, in backward
    model.backward(closure_loss, optimizer, *args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py", line 1370, in backward
    loss.backward(*args, **kwargs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/home/sol/.local/lib/python3.8/site-packages/torch/autograd/function.py", line 253, in apply
    return user_fn(self, *args)
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 119, in backward
    expectation_right = ctx.quantum_circuit(ctx.n_qubits, ctx.backend, ctx.shots, thetas =shift_right[i]).run()
  File "/home/sol/git/QML2/src/layers/quantum_layers.py", line 31, in __init__
    for i in range(len(theta)):
